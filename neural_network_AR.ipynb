{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "training_data, test_data = data[0], data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f10bc9ebac8>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(test_data[54][0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "epochs = 30\n",
    "eta = 5\n",
    "n_input, n_hidden, n_output = 784, 30, 10\n",
    "n = len(training_data)\n",
    "\n",
    "biases = [ np.random.randn(n_hidden, 1), np.random.randn(n_output, 1) ]\n",
    "weights = [ np.random.randn(n_hidden, n_input), np.random.randn(n_output, n_hidden) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return(1 / (1 + np.exp(-x)))\n",
    "\n",
    "def sigma_der(x):\n",
    "    s = sigma(x)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    hidden_z = np.dot(weights[0], x) + biases[0]\n",
    "    hidden_a = sigma(hidden_z)\n",
    "    output_z = np.dot(weights[1], hidden_a) + biases[1]\n",
    "    output_a = sigma(output_z)\n",
    "    return hidden_z, hidden_a, output_z, output_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ -3.90349967],\n",
       "        [-16.67283193],\n",
       "        [ 17.75858448],\n",
       "        [ -5.97459672],\n",
       "        [  5.5963784 ],\n",
       "        [ -2.72450479],\n",
       "        [ -1.5720064 ],\n",
       "        [  8.53042832],\n",
       "        [ -1.25026691],\n",
       "        [ -6.40310439],\n",
       "        [  7.38510994],\n",
       "        [-19.83043971],\n",
       "        [-14.65417038],\n",
       "        [ -5.90930935],\n",
       "        [-12.40353073],\n",
       "        [  2.47770591],\n",
       "        [  5.60777951],\n",
       "        [ -2.11489185],\n",
       "        [ 16.15066471],\n",
       "        [  1.05127836],\n",
       "        [-11.74600258],\n",
       "        [-17.92882641],\n",
       "        [ 15.47392599],\n",
       "        [ -3.48378073],\n",
       "        [-14.12762856],\n",
       "        [  2.83579452],\n",
       "        [ -0.46249458],\n",
       "        [  0.70742438],\n",
       "        [  0.40319137],\n",
       "        [  2.54492151]]), array([[1.97723630e-02],\n",
       "        [5.74223641e-08],\n",
       "        [9.99999981e-01],\n",
       "        [2.53607918e-03],\n",
       "        [9.96302442e-01],\n",
       "        [6.15427764e-02],\n",
       "        [1.71930551e-01],\n",
       "        [9.99802669e-01],\n",
       "        [2.22653938e-01],\n",
       "        [1.65366800e-03],\n",
       "        [9.99379962e-01],\n",
       "        [2.44202136e-09],\n",
       "        [4.32289293e-07],\n",
       "        [2.70671452e-03],\n",
       "        [4.10405588e-06],\n",
       "        [9.22564068e-01],\n",
       "        [9.96344206e-01],\n",
       "        [1.07657816e-01],\n",
       "        [9.99999903e-01],\n",
       "        [7.41020304e-01],\n",
       "        [7.92086217e-06],\n",
       "        [1.63534585e-08],\n",
       "        [9.99999810e-01],\n",
       "        [2.97772578e-02],\n",
       "        [7.31894620e-07],\n",
       "        [9.44579721e-01],\n",
       "        [3.86394208e-01],\n",
       "        [6.69831793e-01],\n",
       "        [5.99454179e-01],\n",
       "        [9.27231595e-01]]), array([[ 5.55367191],\n",
       "        [-6.36285917],\n",
       "        [-2.93558704],\n",
       "        [ 0.67519079],\n",
       "        [-5.77683226],\n",
       "        [ 3.9144797 ],\n",
       "        [ 0.87347341],\n",
       "        [ 3.22910989],\n",
       "        [ 2.09599708],\n",
       "        [-1.64985235]]), array([[0.99614173],\n",
       "        [0.00172146],\n",
       "        [0.05042215],\n",
       "        [0.66266449],\n",
       "        [0.00308894],\n",
       "        [0.98043933],\n",
       "        [0.70546793],\n",
       "        [0.96191516],\n",
       "        [0.89051351],\n",
       "        [0.16112891]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(training_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(x, y):\n",
    "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "    \n",
    "    hidden_z, hidden_a, output_z, output_a = forward(x)\n",
    "    \n",
    "    delta1 = (output_a - y) * sigma_der(output_z)\n",
    "    nabla_b[1] = delta1\n",
    "    nabla_w[1] = np.dot(delta1, hidden_a.T)\n",
    "    \n",
    "    delta2 = np.dot(weights[1].T, delta1) * sigma_der(hidden_z)\n",
    "    nabla_b[0] = delta2\n",
    "    nabla_w[0] = np.dot(delta2, x.T)\n",
    "    \n",
    "    return nabla_b, nabla_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 782 / 10000\n",
      "Epoch 1 : 915 / 10000\n",
      "Epoch 2 : 1005 / 10000\n",
      "Epoch 3 : 1046 / 10000\n",
      "Epoch 4 : 1097 / 10000\n",
      "Epoch 5 : 1121 / 10000\n",
      "Epoch 6 : 1149 / 10000\n",
      "Epoch 7 : 1174 / 10000\n",
      "Epoch 8 : 1201 / 10000\n",
      "Epoch 9 : 1218 / 10000\n",
      "Epoch 10 : 1245 / 10000\n",
      "Epoch 11 : 1265 / 10000\n",
      "Epoch 12 : 1293 / 10000\n",
      "Epoch 13 : 1317 / 10000\n",
      "Epoch 14 : 1337 / 10000\n",
      "Epoch 15 : 1357 / 10000\n",
      "Epoch 16 : 1372 / 10000\n",
      "Epoch 17 : 1383 / 10000\n",
      "Epoch 18 : 1401 / 10000\n",
      "Epoch 19 : 1419 / 10000\n",
      "Epoch 20 : 1428 / 10000\n",
      "Epoch 21 : 1433 / 10000\n",
      "Epoch 22 : 1441 / 10000\n",
      "Epoch 23 : 1457 / 10000\n",
      "Epoch 24 : 1471 / 10000\n",
      "Epoch 25 : 1477 / 10000\n",
      "Epoch 26 : 1487 / 10000\n",
      "Epoch 27 : 1501 / 10000\n",
      "Epoch 28 : 1515 / 10000\n",
      "Epoch 29 : 1529 / 10000\n",
      "Epoch 30 : 1534 / 10000\n",
      "Epoch 31 : 1550 / 10000\n",
      "Epoch 32 : 1563 / 10000\n",
      "Epoch 33 : 1583 / 10000\n",
      "Epoch 34 : 1598 / 10000\n",
      "Epoch 35 : 1611 / 10000\n",
      "Epoch 36 : 1613 / 10000\n",
      "Epoch 37 : 1621 / 10000\n",
      "Epoch 38 : 1635 / 10000\n",
      "Epoch 39 : 1651 / 10000\n",
      "Epoch 40 : 1659 / 10000\n",
      "Epoch 41 : 1668 / 10000\n",
      "Epoch 42 : 1679 / 10000\n",
      "Epoch 43 : 1690 / 10000\n",
      "Epoch 44 : 1707 / 10000\n",
      "Epoch 45 : 1721 / 10000\n",
      "Epoch 46 : 1734 / 10000\n",
      "Epoch 47 : 1757 / 10000\n",
      "Epoch 48 : 1764 / 10000\n",
      "Epoch 49 : 1788 / 10000\n",
      "Epoch 50 : 1803 / 10000\n",
      "Epoch 51 : 1820 / 10000\n",
      "Epoch 52 : 1832 / 10000\n",
      "Epoch 53 : 1854 / 10000\n",
      "Epoch 54 : 1872 / 10000\n",
      "Epoch 55 : 1882 / 10000\n",
      "Epoch 56 : 1904 / 10000\n",
      "Epoch 57 : 1910 / 10000\n",
      "Epoch 58 : 1930 / 10000\n",
      "Epoch 59 : 1959 / 10000\n",
      "Epoch 60 : 1987 / 10000\n",
      "Epoch 61 : 2005 / 10000\n",
      "Epoch 62 : 2026 / 10000\n",
      "Epoch 63 : 2048 / 10000\n",
      "Epoch 64 : 2072 / 10000\n",
      "Epoch 65 : 2098 / 10000\n",
      "Epoch 66 : 2130 / 10000\n",
      "Epoch 67 : 2144 / 10000\n",
      "Epoch 68 : 2174 / 10000\n",
      "Epoch 69 : 2195 / 10000\n",
      "Epoch 70 : 2208 / 10000\n",
      "Epoch 71 : 2226 / 10000\n",
      "Epoch 72 : 2248 / 10000\n",
      "Epoch 73 : 2284 / 10000\n",
      "Epoch 74 : 2312 / 10000\n",
      "Epoch 75 : 2337 / 10000\n",
      "Epoch 76 : 2354 / 10000\n",
      "Epoch 77 : 2366 / 10000\n",
      "Epoch 78 : 2379 / 10000\n",
      "Epoch 79 : 2397 / 10000\n",
      "Epoch 80 : 2419 / 10000\n",
      "Epoch 81 : 2437 / 10000\n",
      "Epoch 82 : 2452 / 10000\n",
      "Epoch 83 : 2469 / 10000\n",
      "Epoch 84 : 2480 / 10000\n",
      "Epoch 85 : 2497 / 10000\n",
      "Epoch 86 : 2513 / 10000\n",
      "Epoch 87 : 2538 / 10000\n",
      "Epoch 88 : 2556 / 10000\n",
      "Epoch 89 : 2578 / 10000\n",
      "Epoch 90 : 2597 / 10000\n",
      "Epoch 91 : 2607 / 10000\n",
      "Epoch 92 : 2623 / 10000\n",
      "Epoch 93 : 2633 / 10000\n",
      "Epoch 94 : 2653 / 10000\n",
      "Epoch 95 : 2673 / 10000\n",
      "Epoch 96 : 2688 / 10000\n",
      "Epoch 97 : 2701 / 10000\n",
      "Epoch 98 : 2718 / 10000\n",
      "Epoch 99 : 2735 / 10000\n"
     ]
    }
   ],
   "source": [
    "biases = [ np.random.randn(n_hidden, 1), np.random.randn(n_output, 1) ]\n",
    "weights = [ np.random.randn(n_hidden, n_input), np.random.randn(n_output, n_hidden) ]\n",
    "eta = 3\n",
    "epoches = 100\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in weights]    \n",
    "    \n",
    "    for x, y in training_data:\n",
    "        delta_b, delta_w = backprop(x, y)\n",
    "        nabla_b = [nb + db for nb, db in zip(nabla_b, delta_b)]\n",
    "        nabla_w = [nw + dw for nw, dw in zip(nabla_w, delta_w)]        \n",
    "    \n",
    "    biases = [b - eta / n * nb for b, nb in zip(biases, nabla_b)]\n",
    "    weights = [w - eta / n * nw for w, nw in zip(weights, nabla_w)]\n",
    "    \n",
    "    s = 0\n",
    "    for x, y in test_data:\n",
    "        _, _, _, pred = forward(x)\n",
    "        s += int(np.argmax(pred) == y)\n",
    "    print(\"Epoch {} : {} / {}\".format(epoch, s, len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 8826 / 10000\n",
      "Epoch 1 : 9067 / 10000\n",
      "Epoch 2 : 9177 / 10000\n",
      "Epoch 3 : 9223 / 10000\n",
      "Epoch 4 : 9295 / 10000\n",
      "Epoch 5 : 9309 / 10000\n",
      "Epoch 6 : 9350 / 10000\n",
      "Epoch 7 : 9342 / 10000\n",
      "Epoch 8 : 9379 / 10000\n",
      "Epoch 9 : 9398 / 10000\n",
      "Epoch 10 : 9409 / 10000\n",
      "Epoch 11 : 9438 / 10000\n",
      "Epoch 12 : 9415 / 10000\n",
      "Epoch 13 : 9426 / 10000\n",
      "Epoch 14 : 9434 / 10000\n",
      "Epoch 15 : 9418 / 10000\n",
      "Epoch 16 : 9429 / 10000\n",
      "Epoch 17 : 9446 / 10000\n",
      "Epoch 18 : 9439 / 10000\n",
      "Epoch 19 : 9452 / 10000\n",
      "Epoch 20 : 9448 / 10000\n",
      "Epoch 21 : 9465 / 10000\n",
      "Epoch 22 : 9453 / 10000\n",
      "Epoch 23 : 9468 / 10000\n",
      "Epoch 24 : 9455 / 10000\n",
      "Epoch 25 : 9467 / 10000\n",
      "Epoch 26 : 9465 / 10000\n",
      "Epoch 27 : 9486 / 10000\n",
      "Epoch 28 : 9472 / 10000\n",
      "Epoch 29 : 9469 / 10000\n",
      "Epoch 30 : 9492 / 10000\n",
      "Epoch 31 : 9475 / 10000\n",
      "Epoch 32 : 9486 / 10000\n",
      "Epoch 33 : 9471 / 10000\n",
      "Epoch 34 : 9475 / 10000\n",
      "Epoch 35 : 9484 / 10000\n",
      "Epoch 36 : 9463 / 10000\n",
      "Epoch 37 : 9466 / 10000\n",
      "Epoch 38 : 9478 / 10000\n",
      "Epoch 39 : 9484 / 10000\n",
      "Epoch 40 : 9470 / 10000\n",
      "Epoch 41 : 9471 / 10000\n",
      "Epoch 42 : 9472 / 10000\n",
      "Epoch 43 : 9473 / 10000\n",
      "Epoch 44 : 9477 / 10000\n",
      "Epoch 45 : 9469 / 10000\n",
      "Epoch 46 : 9473 / 10000\n",
      "Epoch 47 : 9482 / 10000\n",
      "Epoch 48 : 9477 / 10000\n",
      "Epoch 49 : 9483 / 10000\n",
      "Epoch 50 : 9469 / 10000\n",
      "Epoch 51 : 9471 / 10000\n",
      "Epoch 52 : 9475 / 10000\n",
      "Epoch 53 : 9465 / 10000\n",
      "Epoch 54 : 9474 / 10000\n",
      "Epoch 55 : 9466 / 10000\n",
      "Epoch 56 : 9467 / 10000\n",
      "Epoch 57 : 9479 / 10000\n",
      "Epoch 58 : 9463 / 10000\n",
      "Epoch 59 : 9484 / 10000\n",
      "Epoch 60 : 9472 / 10000\n",
      "Epoch 61 : 9460 / 10000\n",
      "Epoch 62 : 9475 / 10000\n",
      "Epoch 63 : 9469 / 10000\n",
      "Epoch 64 : 9469 / 10000\n",
      "Epoch 65 : 9465 / 10000\n",
      "Epoch 66 : 9451 / 10000\n",
      "Epoch 67 : 9462 / 10000\n",
      "Epoch 68 : 9468 / 10000\n",
      "Epoch 69 : 9471 / 10000\n",
      "Epoch 70 : 9464 / 10000\n",
      "Epoch 71 : 9471 / 10000\n",
      "Epoch 72 : 9474 / 10000\n",
      "Epoch 73 : 9466 / 10000\n",
      "Epoch 74 : 9457 / 10000\n",
      "Epoch 75 : 9471 / 10000\n",
      "Epoch 76 : 9476 / 10000\n",
      "Epoch 77 : 9470 / 10000\n",
      "Epoch 78 : 9473 / 10000\n",
      "Epoch 79 : 9475 / 10000\n",
      "Epoch 80 : 9468 / 10000\n",
      "Epoch 81 : 9473 / 10000\n",
      "Epoch 82 : 9482 / 10000\n",
      "Epoch 83 : 9459 / 10000\n",
      "Epoch 84 : 9478 / 10000\n",
      "Epoch 85 : 9473 / 10000\n",
      "Epoch 86 : 9467 / 10000\n",
      "Epoch 87 : 9478 / 10000\n",
      "Epoch 88 : 9475 / 10000\n",
      "Epoch 89 : 9481 / 10000\n",
      "Epoch 90 : 9477 / 10000\n",
      "Epoch 91 : 9469 / 10000\n",
      "Epoch 92 : 9469 / 10000\n",
      "Epoch 93 : 9470 / 10000\n",
      "Epoch 94 : 9462 / 10000\n",
      "Epoch 95 : 9463 / 10000\n",
      "Epoch 96 : 9461 / 10000\n",
      "Epoch 97 : 9478 / 10000\n",
      "Epoch 98 : 9463 / 10000\n",
      "Epoch 99 : 9466 / 10000\n"
     ]
    }
   ],
   "source": [
    "biases = [ np.random.randn(n_hidden, 1), np.random.randn(n_output, 1) ]\n",
    "weights = [ np.random.randn(n_hidden, n_input), np.random.randn(n_output, n_hidden) ]\n",
    "\n",
    "n = len(training_data)\n",
    "mini_batch_size = 30\n",
    "eta = 3\n",
    "epoches = 100\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    random.shuffle(training_data)\n",
    "    mini_batches = [\n",
    "        training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "    for mini_batch in mini_batches:\n",
    "        nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        weights = [w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(weights, nabla_w)]\n",
    "        biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(biases, nabla_b)]\n",
    "    \n",
    "    s = 0\n",
    "    wrong = []\n",
    "    for i,(x, y) in enumerate(test_data):\n",
    "        _, _, _, pred = forward(x)\n",
    "        s += int(np.argmax(pred) == y)\n",
    "        if int(np.argmax(pred)!=y): wrong.append([pred, i])\n",
    "    print(\"Epoch {} : {} / {}\".format(epoch, s, len(test_data)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self, layers_size, training_data, epoches=100, eta=3):\n",
    "        self.layers = layers_size\n",
    "        self.biases = [np.random.randn(i).reshape(i, 1) for i in layers_size[1:]]\n",
    "        self.weights = [np.random.randn(layers_size[i], layers_size[i-1]) for i in range(1, len(layers_size))]\n",
    "        self.epoches = epoches\n",
    "        self.eta = eta\n",
    "        self.training_data = training_data\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.z = []\n",
    "        last_a = x\n",
    "        self.a = [last_a]\n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, last_a) + b\n",
    "            self.z.append(z)\n",
    "            last_a = self.sigma(z)\n",
    "            self.a.append(last_a)\n",
    "    \n",
    "    \n",
    "    def backprop(self, x, y):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "\n",
    "        self.forward_pass(x)\n",
    "\n",
    "        delta = (self.a[-1] - y) * sigma_der(self.z[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, self.a[-2].T())\n",
    "\n",
    "        for l in range(2, len(self.layers)):\n",
    "            delta = np.dot(self.weights[-l+1].T(), delta) * self.sigma_der(self.z[-l])\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, self.a[-l-1].T())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    \n",
    "    def sigma(self, z):\n",
    "        return(1 / (1 + np.exp(-z)))\n",
    "    \n",
    "    def sigma_der(self, z):\n",
    "        s = self.sigma(z)\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def SGD(self, mini_batch_size=30):\n",
    "        for epoch in range(self.epoches):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size] for k in range(0, len(training_data), mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "                nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "                for x, y in mini_batch:\n",
    "                    delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "                    nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "                    nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "                self.weights = [w-(self.eta/len(mini_batch))*nw\n",
    "                                for w, nw in zip(self.weights, nabla_w)]\n",
    "                self.biases = [b-(self.eta/len(mini_batch))*nb\n",
    "                               for b, nb in zip(self.biases, nabla_b)]\n",
    "  \n",
    "            s = 0\n",
    "            for i,(x, y) in enumerate(test_data):\n",
    "                self.forward_pass(x)\n",
    "                s += int(np.argmax(self.a[-1]) == y)\n",
    "            print(\"Epoch {} : {} / {}\".format(epoch, s, len(test_data)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 8775 / 10000\n",
      "Epoch 1 : 9041 / 10000\n",
      "Epoch 2 : 9133 / 10000\n",
      "Epoch 3 : 9218 / 10000\n",
      "Epoch 4 : 9249 / 10000\n",
      "Epoch 5 : 9277 / 10000\n",
      "Epoch 6 : 9313 / 10000\n",
      "Epoch 7 : 9304 / 10000\n",
      "Epoch 8 : 9333 / 10000\n",
      "Epoch 9 : 9342 / 10000\n",
      "Epoch 10 : 9369 / 10000\n",
      "Epoch 11 : 9356 / 10000\n",
      "Epoch 12 : 9390 / 10000\n",
      "Epoch 13 : 9397 / 10000\n",
      "Epoch 14 : 9416 / 10000\n",
      "Epoch 15 : 9405 / 10000\n",
      "Epoch 16 : 9411 / 10000\n",
      "Epoch 17 : 9408 / 10000\n",
      "Epoch 18 : 9391 / 10000\n",
      "Epoch 19 : 9422 / 10000\n",
      "Epoch 20 : 9418 / 10000\n",
      "Epoch 21 : 9415 / 10000\n",
      "Epoch 22 : 9427 / 10000\n",
      "Epoch 23 : 9434 / 10000\n",
      "Epoch 24 : 9440 / 10000\n",
      "Epoch 25 : 9436 / 10000\n",
      "Epoch 26 : 9429 / 10000\n",
      "Epoch 27 : 9435 / 10000\n",
      "Epoch 28 : 9430 / 10000\n",
      "Epoch 29 : 9441 / 10000\n",
      "Epoch 30 : 9431 / 10000\n",
      "Epoch 31 : 9435 / 10000\n",
      "Epoch 32 : 9435 / 10000\n",
      "Epoch 33 : 9438 / 10000\n",
      "Epoch 34 : 9422 / 10000\n",
      "Epoch 35 : 9454 / 10000\n",
      "Epoch 36 : 9445 / 10000\n",
      "Epoch 37 : 9443 / 10000\n",
      "Epoch 38 : 9444 / 10000\n",
      "Epoch 39 : 9466 / 10000\n",
      "Epoch 40 : 9448 / 10000\n",
      "Epoch 41 : 9444 / 10000\n",
      "Epoch 42 : 9453 / 10000\n",
      "Epoch 43 : 9456 / 10000\n",
      "Epoch 44 : 9455 / 10000\n",
      "Epoch 45 : 9455 / 10000\n",
      "Epoch 46 : 9448 / 10000\n",
      "Epoch 47 : 9461 / 10000\n",
      "Epoch 48 : 9467 / 10000\n",
      "Epoch 49 : 9463 / 10000\n",
      "Epoch 50 : 9457 / 10000\n",
      "Epoch 51 : 9468 / 10000\n",
      "Epoch 52 : 9456 / 10000\n",
      "Epoch 53 : 9459 / 10000\n",
      "Epoch 54 : 9454 / 10000\n",
      "Epoch 55 : 9467 / 10000\n",
      "Epoch 56 : 9471 / 10000\n",
      "Epoch 57 : 9464 / 10000\n",
      "Epoch 58 : 9467 / 10000\n",
      "Epoch 59 : 9454 / 10000\n",
      "Epoch 60 : 9464 / 10000\n",
      "Epoch 61 : 9461 / 10000\n",
      "Epoch 62 : 9461 / 10000\n",
      "Epoch 63 : 9452 / 10000\n",
      "Epoch 64 : 9469 / 10000\n",
      "Epoch 65 : 9466 / 10000\n",
      "Epoch 66 : 9461 / 10000\n",
      "Epoch 67 : 9465 / 10000\n",
      "Epoch 68 : 9451 / 10000\n",
      "Epoch 69 : 9462 / 10000\n",
      "Epoch 70 : 9476 / 10000\n",
      "Epoch 71 : 9465 / 10000\n",
      "Epoch 72 : 9467 / 10000\n",
      "Epoch 73 : 9463 / 10000\n",
      "Epoch 74 : 9461 / 10000\n",
      "Epoch 75 : 9462 / 10000\n",
      "Epoch 76 : 9465 / 10000\n",
      "Epoch 77 : 9460 / 10000\n",
      "Epoch 78 : 9468 / 10000\n",
      "Epoch 79 : 9456 / 10000\n",
      "Epoch 80 : 9470 / 10000\n",
      "Epoch 81 : 9467 / 10000\n",
      "Epoch 82 : 9468 / 10000\n",
      "Epoch 83 : 9469 / 10000\n",
      "Epoch 84 : 9451 / 10000\n",
      "Epoch 85 : 9453 / 10000\n",
      "Epoch 86 : 9461 / 10000\n",
      "Epoch 87 : 9457 / 10000\n",
      "Epoch 88 : 9452 / 10000\n",
      "Epoch 89 : 9457 / 10000\n",
      "Epoch 90 : 9464 / 10000\n",
      "Epoch 91 : 9456 / 10000\n",
      "Epoch 92 : 9452 / 10000\n",
      "Epoch 93 : 9466 / 10000\n",
      "Epoch 94 : 9460 / 10000\n",
      "Epoch 95 : 9449 / 10000\n",
      "Epoch 96 : 9453 / 10000\n",
      "Epoch 97 : 9462 / 10000\n",
      "Epoch 98 : 9471 / 10000\n",
      "Epoch 99 : 9456 / 10000\n"
     ]
    }
   ],
   "source": [
    "net = Network([784, 30, 10], training_data, eta=3)\n",
    "net.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
